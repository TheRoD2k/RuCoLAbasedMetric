{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4T-mqWXufogB"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"sylUSksnfrt2"},"source":["# Diploma, Using RuCoLa for summarization quality estimation, 2022\n","\n","Ponomarev Artem, NLP ABBYY, MIPT"]},{"cell_type":"markdown","metadata":{"id":"gW0HZU7JgDVA"},"source":["As the summarization dataset we will use gazeta dataset\n","\n","https://github.com/IlyaGusev/gazeta"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xsDk3-iXhzd_","outputId":"6698ee9f-65fc-4367-85b0-f5b0e10a6c05"},"outputs":[{"name":"stdout","output_type":"stream","text":[" classification_report_optimized.txt    roberta_grammatic_17_epochs\r\n"," ClassifierTraining.ipynb\t        roberta_grammatic_18_epochs\r\n"," cuda_11.0.2_450.51.05_linux.run        roberta_grammatic_19_epochs\r\n"," Diploma.ipynb\t\t\t        roberta_grammatic_2_epochs\r\n"," first_results.csv\t\t        roberta_grammatic_3_epochs\r\n"," gazeta_jsonl\t\t\t        roberta_grammatic_3epochs\r\n"," GeneralClassifier\t\t        roberta_grammatic_4_epochs\r\n"," Lexis_1e6_classifier_checkpoints       roberta_grammatic_5_epochs\r\n"," MachineClassifier\t\t        roberta_grammatic_6_epochs\r\n"," Machine_text_classifier_checkpoints    roberta_grammatic_7_epochs\r\n","'MBartSummarizerOutput (1).txt'         roberta_grammatic_8_epochs\r\n"," MBartSummarizerOutput_gazeta_val.txt   roberta_grammatic_9_epochs\r\n"," MBartSummarizerOutput.txt\t        roberta_machine_0_epochs\r\n"," new_roberta_grammatic_0_epochs         roberta_machine_1_epochs\r\n"," new_roberta_grammatic_1_epochs         roberta_machine_2_epochs\r\n"," new_roberta_grammatic_2_epochs         roberta_machine_3_epochs\r\n"," Pictures\t\t\t        roberta_machine_4_epochs\r\n"," requirements.txt\t\t        roberta_machine_5_epochs\r\n"," roberta_general_0_epochs\t        roberta_machine_6_epochs\r\n"," roberta_general_1_epochs\t        roberta_machine_7_epochs\r\n"," roberta_general_2_epochs\t        roberta_machine_8_epochs\r\n"," roberta_general_3_epochs\t        roberta_machine_9_epochs\r\n"," roberta_general_4_epochs\t        roberta_syntax_0_epochs\r\n"," roberta_general_5_epochs\t        roberta_syntax_1_epochs\r\n"," roberta_general_6_epochs\t        roberta_syntax_2_epochs\r\n"," roberta_general_7_epochs\t        roberta_syntax_3_epochs\r\n"," roberta_general_8_epochs\t        rucola\r\n"," roberta_general_9_epochs\t        RuCoLA-main\r\n"," roberta_grammatic_10_epochs\t        semantics_error_classifier_checkpoints\r\n"," roberta_grammatic_11_epochs\t        SyntaxClassifier\r\n"," roberta_grammatic_12_epochs\t        testdisk.log\r\n"," roberta_grammatic_13_epochs\t        test_trainer\r\n"," roberta_grammatic_14_epochs\t        train_data_loader\r\n"," roberta_grammatic_15_epochs\t        validation_data_loader\r\n"," roberta_grammatic_16_epochs\r\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4f4cjgJo4Ui"},"outputs":[],"source":["# !tar -C ./gazeta_jsonl -xvf gazeta_jsonl.tar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DNti0LD8BMX3","outputId":"463a13ad-0180-4711-bd19-504a25a746a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["5770\n"]}],"source":["data_pd = pd.read_json(\"./gazeta_jsonl/gazeta_test.jsonl\", dtype={ 'text': str, 'summary': str }, lines=True)\n","print(len(data_pd))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgCQpXTNBMX3"},"outputs":[],"source":["DATA_LENGTH = 10000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfLnEByIiq6M"},"outputs":[],"source":["# Open the dataset:\n","data_pd = pd.read_json(\"./gazeta_jsonl/gazeta_val.jsonl\", dtype={ 'text': str, 'summary': str }, nrows=DATA_LENGTH, lines=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4smRtRaF5WI3"},"outputs":[],"source":["data_pd = data_pd[['text', 'summary']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mppGBdEdBMX5","outputId":"dd486bad-62f1-4672-c46f-472d7d3ffc58"},"outputs":[{"data":{"text/plain":["5265"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(data_pd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hluYUoLQBMX5"},"outputs":[],"source":["DATA_LENGTH = min(DATA_LENGTH, len(data_pd))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"XJrAYZht-CaO","outputId":"b768b3ad-8263-4336-d07d-99bea1ff11d4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>После громких приобретений Андре Шюррле, Гуса ...</td>\n","      <td>Московский «Спартак» продолжает активную транс...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Американское издание The National Interest оце...</td>\n","      <td>Издание The National Interest оценило перспект...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Министр иностранных дел России Сергей Лавров с...</td>\n","      <td>Глава МИД России Сергей Лавров заявил, что в 2...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Минфин предложил с января 2020 года увеличить ...</td>\n","      <td>Министерство финансов предлагает вдвое поднять...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Заявление командующего военно-воздушными силам...</td>\n","      <td>Американские ПВО провалились в Саудовской Арав...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  \\\n","0  После громких приобретений Андре Шюррле, Гуса ...   \n","1  Американское издание The National Interest оце...   \n","2  Министр иностранных дел России Сергей Лавров с...   \n","3  Минфин предложил с января 2020 года увеличить ...   \n","4  Заявление командующего военно-воздушными силам...   \n","\n","                                             summary  \n","0  Московский «Спартак» продолжает активную транс...  \n","1  Издание The National Interest оценило перспект...  \n","2  Глава МИД России Сергей Лавров заявил, что в 2...  \n","3  Министерство финансов предлагает вдвое поднять...  \n","4  Американские ПВО провалились в Саудовской Арав...  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["data_pd.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSv43Spbw0Ry","outputId":"ec2ebe1f-44b8-48dd-b464-546eb86f734e"},"outputs":[{"data":{"text/plain":["5265"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["assert DATA_LENGTH == len(data_pd.index)\n","DATA_LENGTH"]},{"cell_type":"markdown","metadata":{"id":"27Kg8BPpBMX6"},"source":["# Используем модель для саммаризации, обученную на датасете gazeta"]},{"cell_type":"markdown","metadata":{"id":"u6zwhfF4BMX6"},"source":["Илья Гусев, 2020, Dataset for Automatic Summarization of Russian News\n","https://huggingface.co/IlyaGusev/mbart_ru_sum_gazeta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKVYcx_bBMX7","outputId":"2566a61d-ce9e-4ac4-d29c-be516e11019e"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-08 14:54:23.296432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-06-08 14:54:23.296447: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]}],"source":["import json\n","import torch\n","from transformers import MBartTokenizer, MBartForConditionalGeneration\n","from datasets import load_dataset\n","from tqdm import tqdm\n","\n","class MBartSummarizer:\n","    def __init__(self, model_name):\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","        print(f\"Model device: {self.device}\")\n","        self.tokenizer = MBartTokenizer.from_pretrained(model_name)\n","        self.model = MBartForConditionalGeneration.from_pretrained(model_name).to(self.device)\n","        \n","    def _gen_batch(self, inputs, batch_size):\n","        batch_start = 0\n","        while batch_start < len(inputs):\n","            yield inputs[batch_start: batch_start + batch_size]\n","            batch_start += batch_size\n","\n","\n","    def predict(\n","        self,\n","        input_records,\n","        max_source_tokens_count=600,\n","        batch_size=4,\n","        print_batch_results=False,\n","        save_in_file=False,\n","        output_file=\"MBartSummarizerOutput.txt\"\n","    ):\n","\n","        batch_count = len(input_records)//batch_size + 1\n","\n","        predictions = []\n","        for batch in tqdm(self._gen_batch(input_records, batch_size), total=batch_count):\n","            texts = [r[\"text\"] for r in batch]\n","            input_ids = self.tokenizer(\n","                texts,\n","                return_tensors=\"pt\",\n","                padding=\"max_length\",\n","                truncation=True,\n","                max_length=max_source_tokens_count\n","            )[\"input_ids\"].to(self.device)\n","\n","            output_ids = self.model.generate(\n","                input_ids=input_ids,\n","                no_repeat_ngram_size=4\n","            )\n","            summaries = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n","            \n","            if print_batch_results:\n","                for s in summaries:\n","                    print(s)\n","            if save_in_file:\n","                self.save(predictions=summaries, output_file=output_file, output_mode=\"a+\")\n","            predictions.extend(summaries)\n","        return predictions\n","    \n","    def save(self, predictions, output_file, output_mode=\"w\"):\n","        with open(output_file, output_mode) as w:\n","            for p in predictions:\n","                w.write(p.strip().replace(\"\\n\", \" \") + \"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3kETmN1BMX7","outputId":"d20e613f-315d-442b-d24a-10f344f2eaf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model device: cuda\n"]}],"source":["summarizer = MBartSummarizer(\"IlyaGusev/mbart_ru_sum_gazeta\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FLz01IMIBMX8"},"outputs":[],"source":["# Запуск теста\n","# gazeta_test = load_dataset('IlyaGusev/gazeta')[\"test\"]\n","# print(type(gazeta_test))\n","# summarizer.predict(list(gazeta_test), print_batch_results=True)"]},{"cell_type":"markdown","metadata":{"id":"j5bHRhzXBMX8"},"source":["# Добавим в наш датасет автоматическую саммаризацию"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mid0Ve3cBMX8"},"outputs":[],"source":["text_data = [{\"text\": text} for text in data_pd[\"text\"]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKXi-wPZBMX8"},"outputs":[],"source":["predictions = []\n","with open(\"MBartSummarizerOutput.txt\", 'r') as file:\n","    for line in file:\n","        predictions.append(line)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdAeGx4PBMX9"},"outputs":[],"source":["# predictions = summarizer.predict(text_data, save_in_file=True, output_file='test.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvAojXgzBMX9"},"outputs":[],"source":["data_pd = data_pd.assign(mbart_gazeta_summary=predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFIxc87fBMX9","outputId":"0456f66d-ed72-4cb2-d540-9b1a6f530725"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>summary</th>\n","      <th>mbart_gazeta_summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>После громких приобретений Андре Шюррле, Гуса Тиля, Эсекьеля Понсе и Джордана Ларссона , а также покупки Резиуана Мирзова московский «Спартак» не планирует закрывать свою летнюю трансферную кампанию. Красно-белые, усилив атакующую линию, взялись за укрепление центральной зоны. Особенно актуальным данный вопрос стал после ухода бразильского хавбека Фернадо в китайский «Бэйцзин Гоань». Тепень за оборонительные действия в «Спартаке» отвечают Роман Зобнин и Аяз Гулиев , однако их игра вызывает больше негативных оценок, нежели уверенности за результат. В связи с провальными переговорами с чешской «Славией» по покупке опорных полузащитников Алекса Крала и Томаша Соучека представители «народной» команды обратили свой взгляд на чемпионат Франции. Nejvyssi vedeni ruskeho klubu navstivilo v minulych dnech Ceskou republiku. I pri veskerem fotbalem respektu k vyznamu tohoto slavneho klubu Slavia odmitla vubec zahajit i zdvorilostni jednani o obou transferech. Ani jeden nyni neni na prodej. Пос...</td>\n","      <td>Московский «Спартак» продолжает активную трансферную кампанию. Очередным новичком красно-белых может стать опорный полузащитник «Ниццы» Адриен Тамез.</td>\n","      <td>Московский «Спартак» не планирует закрывать летнюю трансферную кампанию. Красно-белые, усилив атакующую линию, взялись за укрепление центральной зоны. В связи с провальными переговорами с чешской «Славией» по покупке опорных полузащитников Алекса Крала и Томаша Соучека представители «народной» команды обратили свой взгляд на чемпионат Франции.\\n</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Американское издание The National Interest оценило перспективный авиационный комплекс дальней авиации (ПАК ДА), отметив, что он станет бомбардировщиком шестого поколения. В настоящее время российские разработчики еще создают летательный аппарат. Журналист СМИ Марк Эпископос сравнил его с истребителем пятого поколения Су-57 и выразил мнение, что ПАК ДА станет представителем «шестого поколения». Автор обратил внимание, что это «фундаментально новый бомбардировщик, созданный на основе современных решений». В то время как ранее оружие создавалось на основе советских проектов. У летательного аппарата будут повышенные стелс-характеристики, улучшенная система пилотирования и расширенные боевые возможности. «Самый поразительный аспект ПАК-ДА — это то, насколько он близок к поступлению на вооружение. Первый прототип ожидается в 2021-2022 годах, пробный полет запланирован на 2025-2026 годы, а серийные поставки начнутся в 2028-2029 годах», — обращает внимание Эпископос, добавив, что первые ис...</td>\n","      <td>Издание The National Interest оценило перспективный российский бомбардировщик ПАК ДА, который отличается от своих предшественников современными решениями, в частности, повышенными стелс-характеристиками. Поражает, насколько быстро летательный аппарат поступит на вооружение, отмечает СМИ.</td>\n","      <td>Американское издание The National Interest оценило перспективный авиационный комплекс дальней авиации (ПАК ДА) и сравнило его с истребителем пятого поколения Су-57. В материале отмечается, что это «фундаментально новый бомбардировщик, созданный на основе современных решений», в то время как ранее оружие создавалось на основе советских проектов.\\n</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Министр иностранных дел России Сергей Лавров сообщил, что занимавший на тот момент пост госсекретаря США Джон Керри признавал, что результаты голосования крымчан в марте 2014 года отражают желания жителей полуострова, однако требовал провести повторный референдум в соответствии с нормами международного права. «С какой стати? Если вам все понятно, зачем еще раз гонять людей на какое-то голосование? Надеюсь, Джон [Керри] на меня не обидится», — сказал Лавров в интервью принадлежащему Григорию Березкину РБК. В марте 2014 года в Крыму прошел референдум, по итогам которого полуостров стал территориальной частью России, а Севастополь — городом федерального значения. Украина и большинство западных стран итогов плебисцита не признают. Стоит отметить, что во время своей президентской кампании Дональд Трамп делал заявления касательно Крыма, сказав, что «рассмотрит» этот вопрос, когда станет президентом. Летом 2018 года Трамп возложил вину за ситуацию вокруг Крыма на своего предшественника Ба...</td>\n","      <td>Глава МИД России Сергей Лавров заявил, что в 2014 году США признавали объективность итогов референдума о переходе Крыма под российскую юрсидикцию, но при этом просили провести его повторно. Ранее президент США Дональд Трамп обвинил своего предшественника Барака Обаму в том, что Крым был присоединен к РФ.</td>\n","      <td>Министр иностранных дел России Сергей Лавров заявил, что Джон Керри, занимавший на тот момент пост госсекретаря США, признавал, что результаты голосования крымчан в марте 2014 года отражают желания жителей полуострова, однако требовал провести повторный референдум в соответствии с нормами международного права. Ранее глава Американской торговой палаты в России Алексис Родзянко заявил, что санкции, связанные с Крымом, — «это не очень важный фактор».\\n</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Минфин предложил с января 2020 года увеличить сбор за таможенные операции с посылками из-за рубежа с 250 руб. до 500 руб. Проект постановления опубликован на портале нормативных правовых актов. В документе говорится о ввозе товаров из-за рубежа для личного пользования. С 1 января 2019 года порог беспошлинного ввоза иностранных посылок в Россию был снижен с €1 тыс. до €500. В результате при заказе товаров на сумму свыше €500 в месяц или весом более 31 кг платят сбор в 250 руб. и пошлину в 30% от суммы сверх лимита, но не менее €4 за 1 кг. При этом с 2020 года пошлина будет начисляться на каждую посылку дороже €200. В результате налог составит 15% от суммы превышения, но не менее €2 за 1 кг сверх лимита. Как прокомментировали «Газете.Ru» в Минфине, «речь не идет о введении какого-либо нового вида сборов». «Подготовленным проектом постановления лишь корректируется ставка уже существующего таможенного платежа, причем в строго ограниченных пределах. Действующая сейчас ставка сбора в раз...</td>\n","      <td>Министерство финансов предлагает вдвое поднять сбор за посылки из-за рубежа — с 250 рублей до 500. Причина — инфляция. Интерес россиян к покупкам в иностранных магазинах снизится, однако вряд ли они станут чаще покупать на российских интернет-площадках, отмечают эксперты. И признают — таможенной службе необходимы ресурсы для обработки возросшего объема посылок.</td>\n","      <td>Минфин предлагает с 2020 года увеличить сбор за таможенные операции с посылками из-за рубежа с 250 руб. до 500 рублей. По мнению экспертов, такая мера будет способствовать улучшению финансового здоровья таможенной службы.\\n</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Заявление командующего военно-воздушными силами США в Европе и Африке Джеффри Ли Харригэна о разработке Пентагоном плана по преодолению противовоздушной обороны Калининградской области смотрится странно на фоне провалов американской ПВО в Саудовской Аравии, заметил председатель правительства РФ Дмитрий Медведев. Глава российского кабмина напомнил, что крупнейший союзник США в Персидском заливе — Саудовская Аравия — имеет на вооружении американские зенитно-ракетные комплексы Patriot, которые не смогли сбить ни одного из 10 дронов и крылатых ракет йеменских хуситов, атаковавших гигантский НПЗ в Абкейке нефтяной компании Saudi Aramco в ночь на 14 сентября. «С одной стороны, не все глупые высказывания американских генералов нужно комментировать. Но когда подобное происходит, хочется сказать нашим коллегам: «Они бы лучше занимались своим основным делом и лучше смотрели на то, что происходит с их ПРО», — приводит ФАН слова российского премьер-министра. Официальный представитель министерс...</td>\n","      <td>Американские ПВО провалились в Саудовской Аравии, и в связи с этим заявление главы ВВС США в Европе и Африке Джеффри Ли Харригэна о разработке Пентагоном плана по преодолению ПВО Калининградской области смотрится глупо, указал российский премьер Дмитрий Медведев. Губернатор Калининградской области Антон Алиханов напомнил американскому военному, что «как бы ни был хорош план, всегда есть русские и исторический опыт».</td>\n","      <td>Заявление командующего военно-воздушными силами США в Европе и Африке Джеффри Ли Харригэна о разработке Пентагоном плана по преодолению противовоздушной обороны Калининградской области смотрится странно на фоне провалов американской ПВО в Саудовской Аравии, заметил председатель правительства РФ Дмитрий Медведев. Глава российского кабмина напомнил, что крупнейший союзник США в Персидском заливе — Саудовская Аравия — имеет на вооружении американские зенитно-ракетные комплексы Patriot, которые не смогли сбить ни одного из 10 дронов и крылатых ракет йеменских хуситов, атаковавших гигантский НПЗ в Абкейке нефтяной компании Saudi Aramco в ночь на 14 сентября.\\n</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n","0  После громких приобретений Андре Шюррле, Гуса Тиля, Эсекьеля Понсе и Джордана Ларссона , а также покупки Резиуана Мирзова московский «Спартак» не планирует закрывать свою летнюю трансферную кампанию. Красно-белые, усилив атакующую линию, взялись за укрепление центральной зоны. Особенно актуальным данный вопрос стал после ухода бразильского хавбека Фернадо в китайский «Бэйцзин Гоань». Тепень за оборонительные действия в «Спартаке» отвечают Роман Зобнин и Аяз Гулиев , однако их игра вызывает больше негативных оценок, нежели уверенности за результат. В связи с провальными переговорами с чешской «Славией» по покупке опорных полузащитников Алекса Крала и Томаша Соучека представители «народной» команды обратили свой взгляд на чемпионат Франции. Nejvyssi vedeni ruskeho klubu navstivilo v minulych dnech Ceskou republiku. I pri veskerem fotbalem respektu k vyznamu tohoto slavneho klubu Slavia odmitla vubec zahajit i zdvorilostni jednani o obou transferech. Ani jeden nyni neni na prodej. Пос...   \n","1  Американское издание The National Interest оценило перспективный авиационный комплекс дальней авиации (ПАК ДА), отметив, что он станет бомбардировщиком шестого поколения. В настоящее время российские разработчики еще создают летательный аппарат. Журналист СМИ Марк Эпископос сравнил его с истребителем пятого поколения Су-57 и выразил мнение, что ПАК ДА станет представителем «шестого поколения». Автор обратил внимание, что это «фундаментально новый бомбардировщик, созданный на основе современных решений». В то время как ранее оружие создавалось на основе советских проектов. У летательного аппарата будут повышенные стелс-характеристики, улучшенная система пилотирования и расширенные боевые возможности. «Самый поразительный аспект ПАК-ДА — это то, насколько он близок к поступлению на вооружение. Первый прототип ожидается в 2021-2022 годах, пробный полет запланирован на 2025-2026 годы, а серийные поставки начнутся в 2028-2029 годах», — обращает внимание Эпископос, добавив, что первые ис...   \n","2  Министр иностранных дел России Сергей Лавров сообщил, что занимавший на тот момент пост госсекретаря США Джон Керри признавал, что результаты голосования крымчан в марте 2014 года отражают желания жителей полуострова, однако требовал провести повторный референдум в соответствии с нормами международного права. «С какой стати? Если вам все понятно, зачем еще раз гонять людей на какое-то голосование? Надеюсь, Джон [Керри] на меня не обидится», — сказал Лавров в интервью принадлежащему Григорию Березкину РБК. В марте 2014 года в Крыму прошел референдум, по итогам которого полуостров стал территориальной частью России, а Севастополь — городом федерального значения. Украина и большинство западных стран итогов плебисцита не признают. Стоит отметить, что во время своей президентской кампании Дональд Трамп делал заявления касательно Крыма, сказав, что «рассмотрит» этот вопрос, когда станет президентом. Летом 2018 года Трамп возложил вину за ситуацию вокруг Крыма на своего предшественника Ба...   \n","3  Минфин предложил с января 2020 года увеличить сбор за таможенные операции с посылками из-за рубежа с 250 руб. до 500 руб. Проект постановления опубликован на портале нормативных правовых актов. В документе говорится о ввозе товаров из-за рубежа для личного пользования. С 1 января 2019 года порог беспошлинного ввоза иностранных посылок в Россию был снижен с €1 тыс. до €500. В результате при заказе товаров на сумму свыше €500 в месяц или весом более 31 кг платят сбор в 250 руб. и пошлину в 30% от суммы сверх лимита, но не менее €4 за 1 кг. При этом с 2020 года пошлина будет начисляться на каждую посылку дороже €200. В результате налог составит 15% от суммы превышения, но не менее €2 за 1 кг сверх лимита. Как прокомментировали «Газете.Ru» в Минфине, «речь не идет о введении какого-либо нового вида сборов». «Подготовленным проектом постановления лишь корректируется ставка уже существующего таможенного платежа, причем в строго ограниченных пределах. Действующая сейчас ставка сбора в раз...   \n","4  Заявление командующего военно-воздушными силами США в Европе и Африке Джеффри Ли Харригэна о разработке Пентагоном плана по преодолению противовоздушной обороны Калининградской области смотрится странно на фоне провалов американской ПВО в Саудовской Аравии, заметил председатель правительства РФ Дмитрий Медведев. Глава российского кабмина напомнил, что крупнейший союзник США в Персидском заливе — Саудовская Аравия — имеет на вооружении американские зенитно-ракетные комплексы Patriot, которые не смогли сбить ни одного из 10 дронов и крылатых ракет йеменских хуситов, атаковавших гигантский НПЗ в Абкейке нефтяной компании Saudi Aramco в ночь на 14 сентября. «С одной стороны, не все глупые высказывания американских генералов нужно комментировать. Но когда подобное происходит, хочется сказать нашим коллегам: «Они бы лучше занимались своим основным делом и лучше смотрели на то, что происходит с их ПРО», — приводит ФАН слова российского премьер-министра. Официальный представитель министерс...   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                               summary  \\\n","0                                                                                                                                                                                                                                                                                Московский «Спартак» продолжает активную трансферную кампанию. Очередным новичком красно-белых может стать опорный полузащитник «Ниццы» Адриен Тамез.   \n","1                                                                                                                                     Издание The National Interest оценило перспективный российский бомбардировщик ПАК ДА, который отличается от своих предшественников современными решениями, в частности, повышенными стелс-характеристиками. Поражает, насколько быстро летательный аппарат поступит на вооружение, отмечает СМИ.   \n","2                                                                                                                    Глава МИД России Сергей Лавров заявил, что в 2014 году США признавали объективность итогов референдума о переходе Крыма под российскую юрсидикцию, но при этом просили провести его повторно. Ранее президент США Дональд Трамп обвинил своего предшественника Барака Обаму в том, что Крым был присоединен к РФ.   \n","3                                                          Министерство финансов предлагает вдвое поднять сбор за посылки из-за рубежа — с 250 рублей до 500. Причина — инфляция. Интерес россиян к покупкам в иностранных магазинах снизится, однако вряд ли они станут чаще покупать на российских интернет-площадках, отмечают эксперты. И признают — таможенной службе необходимы ресурсы для обработки возросшего объема посылок.   \n","4  Американские ПВО провалились в Саудовской Аравии, и в связи с этим заявление главы ВВС США в Европе и Африке Джеффри Ли Харригэна о разработке Пентагоном плана по преодолению ПВО Калининградской области смотрится глупо, указал российский премьер Дмитрий Медведев. Губернатор Калининградской области Антон Алиханов напомнил американскому военному, что «как бы ни был хорош план, всегда есть русские и исторический опыт».   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      mbart_gazeta_summary  \n","0                                                                                                                                                                                                                                                                                                                              Московский «Спартак» не планирует закрывать летнюю трансферную кампанию. Красно-белые, усилив атакующую линию, взялись за укрепление центральной зоны. В связи с провальными переговорами с чешской «Славией» по покупке опорных полузащитников Алекса Крала и Томаша Соучека представители «народной» команды обратили свой взгляд на чемпионат Франции.\\n  \n","1                                                                                                                                                                                                                                                                                                                             Американское издание The National Interest оценило перспективный авиационный комплекс дальней авиации (ПАК ДА) и сравнило его с истребителем пятого поколения Су-57. В материале отмечается, что это «фундаментально новый бомбардировщик, созданный на основе современных решений», в то время как ранее оружие создавалось на основе советских проектов.\\n  \n","2                                                                                                                                                                                                                    Министр иностранных дел России Сергей Лавров заявил, что Джон Керри, занимавший на тот момент пост госсекретаря США, признавал, что результаты голосования крымчан в марте 2014 года отражают желания жителей полуострова, однако требовал провести повторный референдум в соответствии с нормами международного права. Ранее глава Американской торговой палаты в России Алексис Родзянко заявил, что санкции, связанные с Крымом, — «это не очень важный фактор».\\n  \n","3                                                                                                                                                                                                                                                                                                                                                                                                                                                          Минфин предлагает с 2020 года увеличить сбор за таможенные операции с посылками из-за рубежа с 250 руб. до 500 рублей. По мнению экспертов, такая мера будет способствовать улучшению финансового здоровья таможенной службы.\\n  \n","4  Заявление командующего военно-воздушными силами США в Европе и Африке Джеффри Ли Харригэна о разработке Пентагоном плана по преодолению противовоздушной обороны Калининградской области смотрится странно на фоне провалов американской ПВО в Саудовской Аравии, заметил председатель правительства РФ Дмитрий Медведев. Глава российского кабмина напомнил, что крупнейший союзник США в Персидском заливе — Саудовская Аравия — имеет на вооружении американские зенитно-ракетные комплексы Patriot, которые не смогли сбить ни одного из 10 дронов и крылатых ракет йеменских хуситов, атаковавших гигантский НПЗ в Абкейке нефтяной компании Saudi Aramco в ночь на 14 сентября.\\n  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# pd.options.display.max_colwidth = 50\n","pd.options.display.max_colwidth = 1000\n","data_pd.head()"]},{"cell_type":"markdown","metadata":{"id":"f2Syzxtvdrjb"},"source":["# Получим оценки саммаризации через существующие метрики"]},{"cell_type":"markdown","metadata":{"id":"Mc5OYY-SeZih"},"source":["# BLEU Experiments (В этом разделе я больше играюсь с метрикой, чем делаю что-то полезное)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JMqIK6MHBMX9"},"outputs":[],"source":["from tqdm import tqdm\n","from nltk.translate.bleu_score import (\n","    sentence_bleu,\n","    corpus_bleu\n",")\n","\n","class BLEUMetrics:\n","    @staticmethod\n","    def get_bleu_array(data, ref_column_name, column_name):\n","        bleu_score_array = np.zeros(DATA_LENGTH)\n","        for i, (ref, summary) in tqdm(enumerate(zip(data[ref_column_name].astype(str), data[column_name].astype(str))), total=DATA_LENGTH):\n","            bleu_score_array[i] = sentence_bleu([ref.split()], summary.split())\n","        return bleu_score_array\n","    \n","    @staticmethod\n","    def get_corpus_bleu(data, ref_column_name, column_name):\n","        bleu_score_whole_corpus = corpus_bleu(\n","            [[ref.split()] for ref in list(data[ref_column_name].astype(str))],\n","            [summary.split() for summary in list(data[column_name].astype(str))]\n","        )\n","        return bleu_score_whole_corpus\n","        "]},{"cell_type":"markdown","metadata":{"id":"yYFnKjDUBMX-"},"source":["## Посмотрим на метрику по датасету для референса и сгенерированного summary относительно текста:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":511},"id":"i1jghp7IqUy5","outputId":"e5fce269-71f7-406e-d682-fd86b37240a0"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|                                                                                                                                                                                                                               | 0/5265 [00:00<?, ?it/s]/home/bart/.local/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/home/bart/.local/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","  6%|█████████████▌                                                                                                                                                                                                     | 338/5265 [00:00<00:02, 1769.71it/s]/home/bart/.local/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5265/5265 [00:02<00:00, 2170.12it/s]"]},{"name":"stdout","output_type":"stream","text":["Среднее значение BLEU референса к тексту: 7.865605738814234e-06\n","Минимальное значение BLEU референса к тексту: 1.1640585762514036e-246\n","Максимальное значение BLEU референса к тексту: 0.002930834547642167\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["bleu_ref_score_array = BLEUMetrics.get_bleu_array(data_pd, \"text\", \"summary\")\n","print(f\"Среднее значение BLEU референса к тексту: {bleu_ref_score_array.mean()}\")\n","print(f\"Минимальное значение BLEU референса к тексту: {bleu_ref_score_array.min()}\")\n","print(f\"Максимальное значение BLEU референса к тексту: {bleu_ref_score_array.max()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNSLPWtmBMX-","outputId":"f28d88cd-e962-4af9-e357-ea0e6cddc361"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5265/5265 [00:02<00:00, 2188.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Среднее значение BLEU сгенерированного summary к тексту: 0.00012069532314052639\n","Минимальное значение BLEU сгенерированного summary к тексту: 2.088854940075572e-257\n","Максимальное значение BLEU сгенерированного summary к тексту: 0.024948333613462017\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["bleu_generated_score_array = BLEUMetrics.get_bleu_array(data_pd, \"text\", \"mbart_gazeta_summary\")\n","print(f\"Среднее значение BLEU сгенерированного summary к тексту: {bleu_generated_score_array.mean()}\")\n","print(f\"Минимальное значение BLEU сгенерированного summary к тексту: {bleu_generated_score_array.min()}\")\n","print(f\"Максимальное значение BLEU сгенерированного summary к тексту: {bleu_generated_score_array.max()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7QE9Gs-BMX-","outputId":"10ba1526-bcbf-4901-f07e-75c0041e0150"},"outputs":[{"name":"stdout","output_type":"stream","text":["Отношение среднего BLEU референсного к сгенерированному: 0.06516910128867426\n","Отношение минимального BLEU референсного к сгенерированному: 55727114119.72387\n","Отношение максимального BLEU референсного к сгенерированному: 0.11747616466298579\n"]}],"source":["print(f\"Отношение среднего BLEU референсного к сгенерированному: {bleu_ref_score_array.mean()/bleu_generated_score_array.mean()}\")\n","print(f\"Отношение минимального BLEU референсного к сгенерированному: {bleu_ref_score_array.min()/bleu_generated_score_array.min()}\")\n","print(f\"Отношение максимального BLEU референсного к сгенерированному: {bleu_ref_score_array.max()/bleu_generated_score_array.max()}\")"]},{"cell_type":"markdown","metadata":{"id":"WyEj8sjhBMX-"},"source":["Данные результаты можно объяснить тем, что BLEU смотрит на n-граммы, а сгенерированный текст по своей структуре ближе к исходному. Что, в прочем, не говорит о том, что сгенерированный текст лучше референсного в качестве summary."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0qKTXqE3nZP","outputId":"af4c1b7f-cce2-44f0-e3ac-1edd055e520c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Значение BLEU по корпусу: 5.32300723880786e-07\n"]}],"source":["bleu_ref_score_whole_corpus = BLEUMetrics.get_corpus_bleu(data_pd, \"text\", \"summary\")\n","print(f\"Значение BLEU по корпусу: {bleu_ref_score_whole_corpus}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ua2yVOnKBMX_","outputId":"970d3225-e628-4fc3-cb5d-5efa769b71f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Значение BLEU по корпусу: 3.5526175790281664e-06\n"]}],"source":["bleu_generated_score_whole_corpus = BLEUMetrics.get_corpus_bleu(data_pd, \"text\", \"mbart_gazeta_summary\")\n","print(f\"Значение BLEU по корпусу: {bleu_generated_score_whole_corpus}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8amqZ5_BMX_","outputId":"b084b4f9-42be-41ea-c3b9-38e28a7a7741"},"outputs":[{"name":"stdout","output_type":"stream","text":["Отношение BLEU референсного summary к сгенерированному на корпусе: 0.14983338680275265\n"]}],"source":["print(f\"Отношение BLEU референсного summary к сгенерированному на корпусе: {bleu_ref_score_whole_corpus/bleu_generated_score_whole_corpus}\")"]},{"cell_type":"markdown","metadata":{"id":"dFTJFGPhBMX_"},"source":["Результат аналогичен предыдущему эксперименту. Отличающиеся данные связаны с иной методикой подсчета BLEU на корпусе (https://www.nltk.org/api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.corpus_bleu)"]},{"cell_type":"markdown","metadata":{"id":"E4KshC1CBMX_"},"source":["Очевидно, подобный подход к оценке саммаризации не подходит. Причина в том, что BLEU сравнивает n-граммы, в результате чего сильно отличающиеся тексты не получат высокий результат при оценке."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HlxjcEB9BMX_"},"outputs":[],"source":["metrics_results = pd.DataFrame(columns=[\"BLEU\", \"ROUGE_1\", \"ROUGE_2\", \"ROUGE_L\", \"ROUGE_L_SUM\", \"METEOR\", \"RUCOLA_METRIC\"])\n","metrics_results.loc[0] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9HnJwY4pBMYA","outputId":"d753fcc9-902b-47b2-f4b0-90e8a91218c2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BLEU</th>\n","      <th>ROUGE_1</th>\n","      <th>ROUGE_2</th>\n","      <th>ROUGE_L</th>\n","      <th>ROUGE_L_SUM</th>\n","      <th>METEOR</th>\n","      <th>RUCOLA_METRIC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   BLEU  ROUGE_1  ROUGE_2  ROUGE_L  ROUGE_L_SUM  METEOR  RUCOLA_METRIC\n","0   0.0      0.0      0.0      0.0          0.0     0.0            0.0"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["metrics_results.head()"]},{"cell_type":"markdown","metadata":{"id":"sIWv7LzlBMYA"},"source":["## Посмотрим на BLEU между референсом и данными, полученными при машинной саммаризации:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDP9qEvdBMYA","outputId":"97797f24-47a0-44d2-eb5e-ec864a373ffe"},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU сгенерированного summary относительно референсного: 0.08943549525680812\n"]}],"source":["bleu_ref_generated_score = BLEUMetrics.get_corpus_bleu(data_pd, \"summary\", \"mbart_gazeta_summary\")\n","print(f\"BLEU сгенерированного summary относительно референсного: {bleu_ref_generated_score}\")\n","metrics_results.loc[0][\"BLEU\"] = bleu_ref_generated_score"]},{"cell_type":"markdown","source":["# Metrics PD"],"metadata":{"id":"Rdgv4gHV3bSy"}},{"cell_type":"code","source":["metrics_results = pd.DataFrame(columns=[\"BLEU\", \"ROUGE_1\", \"ROUGE_2\", \"ROUGE_L\", \"ROUGE_L_SUM\", \"METEOR\", \"RUCOLA_METRIC\"])\n","metrics_results.loc[0] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"],"metadata":{"id":"W65KQQOj3fCs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics_results.head()"],"metadata":{"id":"iG7WOIZj3iL5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# BLEU"],"metadata":{"id":"-XLiZfX93RFG"}},{"cell_type":"markdown","metadata":{"id":"mPSkIwooBMYA"},"source":["Значения метрики довольно низки, но примерно соответствуют результатам автора модели (12.4 BLEU), https://github.com/IlyaGusev/summarus#results-2), что подтверждает корректность эксперимента"]},{"cell_type":"code","source":["from tqdm import tqdm\n","from nltk.translate.bleu_score import (\n","    sentence_bleu,\n","    corpus_bleu\n",")\n","\n","class BLEUMetrics:\n","    @staticmethod\n","    def get_bleu_array(data, ref_column_name, column_name):\n","        bleu_score_array = np.zeros(DATA_LENGTH)\n","        for i, (ref, summary) in tqdm(enumerate(zip(data[ref_column_name].astype(str), data[column_name].astype(str))), total=DATA_LENGTH):\n","            bleu_score_array[i] = sentence_bleu([ref.split()], summary.split())\n","        return bleu_score_array\n","    \n","    @staticmethod\n","    def get_corpus_bleu(data, ref_column_name, column_name):\n","        bleu_score_whole_corpus = corpus_bleu(\n","            [[ref.split()] for ref in list(data[ref_column_name].astype(str))],\n","            [summary.split() for summary in list(data[column_name].astype(str))]\n","        )\n","        return bleu_score_whole_corpus"],"metadata":{"id":"nUoUmvgd3Ld6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bleu_ref_generated_score = BLEUMetrics.get_corpus_bleu(data_pd, \"summary\", \"mbart_gazeta_summary\")\n","print(f\"BLEU сгенерированного summary относительно референсного: {bleu_ref_generated_score}\")\n","metrics_results.loc[0][\"BLEU\"] = bleu_ref_generated_score"],"metadata":{"id":"fmtfE3W33X09"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vVKxXx7SBMYA"},"source":["# ROUGE"]},{"cell_type":"markdown","metadata":{"id":"IVA0RbxjBMYA"},"source":["Пример использования"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DafeBXNyBMYA","outputId":"e1473805-23b4-46ba-d616-d4a6ce62c7d6"},"outputs":[{"name":"stderr","output_type":"stream","text":["Couldn't find a directory or a metric named 'rouge' in this version. It was picked from the master branch on github instead.\n"]},{"name":"stdout","output_type":"stream","text":["['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n","1.0\n"]},{"ename":"AttributeError","evalue":"'numpy.float64' object has no attribute 'mid'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrouge1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[38;5;241m.\u001b[39mfmeasure)\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'mid'"]}],"source":["import evaluate\n","rouge = evaluate.load('rouge')\n","predictions = [\"hello there\", \"general kenobi\"]\n","references = [\"hello there\", \"general kenobi\"]\n","results = rouge.compute(predictions=predictions,\n","                                             references=references)\n","print(list(results.keys()))\n","# ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n","print(results[\"rouge1\"])\n","# AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n","print(results[\"rouge1\"].mid.fmeasure)\n","# 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkj1b29IBMYB","outputId":"7a6d8450-c24f-4bd3-8f49-e4d87cddd5b7"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-07-04 03:46:05.507417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-07-04 03:46:05.507432: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","Couldn't find a directory or a metric named 'rouge' in this version. It was picked from the master branch on github instead.\n"]}],"source":["import evaluate\n","rouge = evaluate.load('rouge')\n","predictions = data_pd[\"mbart_gazeta_summary\"].to_numpy()\n","references = data_pd[\"summary\"].to_numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IANhJ-Z8BMYB"},"outputs":[],"source":["results = rouge.compute(predictions=predictions,\n","                                             references=references)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROfLdG5vBMYB"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUzfEgYzBMYB","outputId":"24497ddb-2da8-4d84-c79a-bcaa3da2d8b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n","{'rouge1': 0.21697164382740097, 'rouge2': 0.05542420267954569, 'rougeL': 0.21087714568907878, 'rougeLsum': 0.2106565781688676}\n","rouge1\t\t 0.21697164382740097\n","rouge2\t\t 0.05542420267954569\n","rougeL\t\t 0.21087714568907878\n","rougeLsum\t 0.2106565781688676\n"]}],"source":["print(list(results.keys()))\n","print(results)\n","\n","print(\"rouge1\\t\\t\", results[\"rouge1\"])#.mid.fmeasure)\n","metrics_results.loc[0][\"ROUGE_1\"] = results[\"rouge1\"]#.mid.fmeasure\n","\n","print(\"rouge2\\t\\t\", results[\"rouge2\"])#.mid.fmeasure)\n","metrics_results.loc[0][\"ROUGE_2\"] = results[\"rouge2\"]#.mid.fmeasure\n","\n","print(\"rougeL\\t\\t\", results[\"rougeL\"])#.mid.fmeasure)\n","metrics_results.loc[0][\"ROUGE_L\"] = results[\"rougeL\"]# .mid.fmeasure\n","\n","print(\"rougeLsum\\t\", results[\"rougeLsum\"])#.mid.fmeasure)\n","metrics_results.loc[0][\"ROUGE_L_SUM\"] = results[\"rougeLsum\"]#.mid.fmeasure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwZcrZJUBMYB","outputId":"0aa1ad64-ea92-4fd2-d326-792b3a30d765"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BLEU</th>\n","      <th>ROUGE_1</th>\n","      <th>ROUGE_2</th>\n","      <th>ROUGE_L</th>\n","      <th>ROUGE_L_SUM</th>\n","      <th>METEOR</th>\n","      <th>RUCOLA_METRIC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.089435</td>\n","      <td>0.216972</td>\n","      <td>0.055424</td>\n","      <td>0.210877</td>\n","      <td>0.210657</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       BLEU   ROUGE_1   ROUGE_2   ROUGE_L  ROUGE_L_SUM  METEOR  RUCOLA_METRIC\n","0  0.089435  0.216972  0.055424  0.210877     0.210657     0.0            0.0"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["metrics_results.head()"]},{"cell_type":"markdown","metadata":{"id":"49hbDjm8BMYB"},"source":["# METEOR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJTJIOqKBMYB","outputId":"5c66ab3b-749e-466e-8250-463975e13dbf"},"outputs":[{"name":"stderr","output_type":"stream","text":["Couldn't find a directory or a metric named 'meteor' in this version. It was picked from the master branch on github instead.\n","[nltk_data] Downloading package wordnet to /home/bart/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /home/bart/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /home/bart/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["meteor = evaluate.load('meteor')\n","# predictions = [\"It is a guide to action which ensures that the military always obeys the commands of the party\"]\n","# references = [\"It is a guide to action that ensures that the military will forever heed Party commands\"]\n","results = meteor.compute(predictions=predictions, references=references)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3v7_79rVBMYC","outputId":"82dc4236-eedf-4ffb-d8aa-9063acde2aa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'meteor': 0.29448801268855873}\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Z-LWlocBMYC"},"outputs":[],"source":["metrics_results.loc[0][\"METEOR\"] = results[\"meteor\"]"]},{"cell_type":"markdown","metadata":{"id":"-iZUb6tOBMYC"},"source":["# Соберем нашу метрику из обученных классификаторов"]},{"cell_type":"markdown","metadata":{"id":"T8Q-bx8-BMYC"},"source":["Для этого будем использовать RuRoberta-large https://huggingface.co/sberbank-ai/ruRoberta-large\n","\n","Обучение классификаторов можно найти в ноутбуке **ClassifierTraining** (**ВНИМАНИЕ**! Код этого ноутбука - черновой и содержит почти все попытки в неотжатом виде; заходить на свой страх и риск, особенно со слабым железом)"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kamfHatNBmMO","executionInfo":{"status":"ok","timestamp":1656991502387,"user_tz":-180,"elapsed":20285,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"8a341926-d6a0-4074-8eb3-013a32dfcaf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install sacremoses\n","!pip install -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZCLqv77EPL1","executionInfo":{"status":"ok","timestamp":1656975219087,"user_tz":-180,"elapsed":21000,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"b56136cb-a2d7-4cd6-f92a-2fbd234d997b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (0.0.53)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2022.6.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 1)) (4.64.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (7.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 3)) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 4)) (1.3.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 5)) (1.11.0+cu113)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 6)) (0.1.96)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (2.3.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 8)) (4.20.1)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 9)) (0.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (3.6.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.4.0)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.5.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.1.1)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (4.10.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.3.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (1.0.18)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.8.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (2.6.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (57.4.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (2.15.3)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (4.10.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (21.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (4.11.4)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.7.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (4.1.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (3.8.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (2.11.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (1.8.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.6.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (23.1.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 4)) (2022.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (3.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (2.23.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (0.3.5.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (0.70.13)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (2022.5.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (0.8.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (0.18.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (21.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (3.8.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (2.10)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 8)) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 8)) (2022.6.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 9)) (1.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (1.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (2.0.12)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 7)) (1.7.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (2.0.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.6.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.8.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (1.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (5.0.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 2)) (0.5.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 9)) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 9)) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r /content/gdrive/MyDrive/DiplomaExp/requirements.txt (line 9)) (1.1.0)\n"]}]},{"cell_type":"code","source":["DRIVE_PREFIX = \"/content/gdrive/MyDrive/DiplomaExp\""],"metadata":{"id":"9nZiiAGrBv1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShRIaQRkBMYC"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import *\n","from tqdm import tqdm, trange\n","from ast import literal_eval\n","\n","\n","class GlobalClassifier:\n","    def __init__(self):\n","        self.tokenizer = RobertaTokenizer.from_pretrained('sberbank-ai/ruRoberta-large', do_lower_case=False) \n","        state_dict = torch.load(f\"{DRIVE_PREFIX}/roberta_general_8_epochs\")\n","        self.model = RobertaForSequenceClassification.from_pretrained(\"sberbank-ai/ruRoberta-large\", state_dict=state_dict, num_labels=1)\n","\n","        self.model.load_state_dict(state_dict)\n","        self.device = 'cuda'\n","        self.model.cuda()\n","    \n","    def __call__(self, sentence):\n","        texts = [sentence]\n","        encodings = self.tokenizer.batch_encode_plus(texts, padding='longest')\n","        input_ids = encodings['input_ids']\n","        attention_masks = encodings['attention_mask']\n","        \n","        validation_inputs = torch.tensor(input_ids)\n","        validation_masks = torch.tensor(attention_masks)\n","        \n","        validation_data = TensorDataset(validation_inputs, validation_masks)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=14)\n","        \n","        num_labels = 1    \n","        pred_labels = []\n","        for i, batch in enumerate(validation_dataloader):\n","            batch = tuple(t.to(self.device) for t in batch)\n","            b_input_ids, b_input_mask = batch\n","            with torch.no_grad():\n","                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","                b_logit_pred = outs[0]\n","\n","                pred_label = torch.sigmoid(b_logit_pred)\n","\n","                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","                pred_label = pred_label.to(self.device).cpu().numpy()\n","\n","            pred_labels.append(pred_label)\n","\n","        pred_labels = [item for sublist in pred_labels for item in sublist]\n","\n","        threshold = 0.65\n","        pred_bools = [pl>threshold for pl in pred_labels]\n","        return pred_bools[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-Q7rUHrBMYC"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import *\n","from tqdm import tqdm, trange\n","from ast import literal_eval\n","\n","\n","class MachineClassifier:\n","    def __init__(self):\n","        self.tokenizer = RobertaTokenizer.from_pretrained('sberbank-ai/ruRoberta-large', do_lower_case=False) \n","        state_dict = torch.load(f\"{DRIVE_PREFIX}/roberta_machine_8_epochs\")\n","        self.model = RobertaForSequenceClassification.from_pretrained(\"sberbank-ai/ruRoberta-large\", state_dict=state_dict, num_labels=1)\n","        self.model.load_state_dict(state_dict)\n","        self.device = 'cuda'\n","        self.model.cuda()\n","    \n","    def __call__(self, sentence):\n","        texts = [sentence]\n","        encodings = self.tokenizer.batch_encode_plus(texts, padding='longest')\n","        input_ids = encodings['input_ids']\n","        attention_masks = encodings['attention_mask']\n","        \n","        validation_inputs = torch.tensor(input_ids)\n","        validation_masks = torch.tensor(attention_masks)\n","        \n","        validation_data = TensorDataset(validation_inputs, validation_masks)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=14)\n","        \n","        num_labels = 1    \n","        pred_labels = []\n","        for i, batch in enumerate(validation_dataloader):\n","            batch = tuple(t.to(self.device) for t in batch)\n","            b_input_ids, b_input_mask = batch\n","            with torch.no_grad():\n","                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","                b_logit_pred = outs[0]\n","\n","                pred_label = torch.sigmoid(b_logit_pred)\n","\n","                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","                pred_label = pred_label.to(self.device).cpu().numpy()\n","\n","            pred_labels.append(pred_label)\n","\n","        pred_labels = [item for sublist in pred_labels for item in sublist]\n","\n","        threshold = 0.61\n","        pred_bools = [pl>threshold for pl in pred_labels]\n","        return pred_bools[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eycGPLWBMYD"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import *\n","from tqdm import tqdm, trange\n","from ast import literal_eval\n","\n","\n","class SyntaxClassifier:\n","    def __init__(self):\n","        self.tokenizer = RobertaTokenizer.from_pretrained('sberbank-ai/ruRoberta-large', do_lower_case=False) \n","        state_dict = torch.load(f\"{DRIVE_PREFIX}/roberta_syntax_2_epochs\")\n","        self.model = RobertaForSequenceClassification.from_pretrained(\"sberbank-ai/ruRoberta-large\", state_dict=state_dict, num_labels=1)\n","\n","        self.model.load_state_dict(state_dict)\n","        self.device = 'cuda'\n","        self.model.cuda()\n","    \n","    def __call__(self, sentence):\n","        texts = [sentence]\n","        encodings = self.tokenizer.batch_encode_plus(texts, padding='longest')\n","        input_ids = encodings['input_ids']\n","        attention_masks = encodings['attention_mask']\n","        \n","        validation_inputs = torch.tensor(input_ids)\n","        validation_masks = torch.tensor(attention_masks)\n","        \n","        validation_data = TensorDataset(validation_inputs, validation_masks)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=14)\n","        \n","        num_labels = 1    \n","        pred_labels = []\n","        for i, batch in enumerate(validation_dataloader):\n","            batch = tuple(t.to(self.device) for t in batch)\n","            b_input_ids, b_input_mask = batch\n","            with torch.no_grad():\n","                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","                b_logit_pred = outs[0]\n","\n","                pred_label = torch.sigmoid(b_logit_pred)\n","\n","                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","                pred_label = pred_label.to(self.device).cpu().numpy()\n","\n","            pred_labels.append(pred_label)\n","\n","        pred_labels = [item for sublist in pred_labels for item in sublist]\n","\n","        threshold = 0.25\n","        pred_bools = [pl>threshold for pl in pred_labels]\n","        return pred_bools[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-g96eccaBMYD"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import *\n","from tqdm import tqdm, trange\n","from ast import literal_eval\n","\n","\n","class HallucinationClassifier:\n","    def __init__(self):\n","        self.tokenizer = RobertaTokenizer.from_pretrained('sberbank-ai/ruRoberta-large', do_lower_case=False) \n","        state_dict = torch.load(f\"{DRIVE_PREFIX}/roberta_hallucination_6_epochs\")\n","        self.model = RobertaForSequenceClassification.from_pretrained(\"sberbank-ai/ruRoberta-large\", state_dict=state_dict, num_labels=1)\n","\n","        self.model.load_state_dict(state_dict)\n","        self.device = 'cuda'\n","        self.model.cuda()\n","    \n","    def __call__(self, sentence):\n","        texts = [sentence]\n","        encodings = self.tokenizer.batch_encode_plus(texts, padding='longest')\n","        input_ids = encodings['input_ids']\n","        attention_masks = encodings['attention_mask']\n","        \n","        validation_inputs = torch.tensor(input_ids)\n","        validation_masks = torch.tensor(attention_masks)\n","        \n","        validation_data = TensorDataset(validation_inputs, validation_masks)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=14)\n","        \n","        num_labels = 1    \n","        pred_labels = []\n","        for i, batch in enumerate(validation_dataloader):\n","            batch = tuple(t.to(self.device) for t in batch)\n","            b_input_ids, b_input_mask = batch\n","            with torch.no_grad():\n","                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","                b_logit_pred = outs[0]\n","\n","                pred_label = torch.sigmoid(b_logit_pred)\n","\n","                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","                pred_label = pred_label.to(self.device).cpu().numpy()\n","\n","            pred_labels.append(pred_label)\n","\n","        pred_labels = [item for sublist in pred_labels for item in sublist]\n","\n","        threshold = 0.9\n","        pred_bools = [pl>threshold for pl in pred_labels]\n","        return pred_bools[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNG0XYvUBMYD"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import *\n","from tqdm import tqdm, trange\n","from ast import literal_eval\n","\n","\n","class SemanticsClassifier: \n","    def __init__(self):\n","        self.tokenizer = RobertaTokenizer.from_pretrained('sberbank-ai/ruRoberta-large', do_lower_case=False) \n","        state_dict = torch.load(f\"{DRIVE_PREFIX}/roberta_semantics_8_epochs\")\n","        self.model = RobertaForSequenceClassification.from_pretrained(\"sberbank-ai/ruRoberta-large\", state_dict=state_dict, num_labels=1)\n","\n","        self.model.load_state_dict(state_dict)\n","        self.device = 'cuda'\n","        self.model.cuda()\n","    \n","    def __call__(self, sentence):\n","        texts = [sentence]\n","        encodings = self.tokenizer.batch_encode_plus(texts, padding='longest')\n","        input_ids = encodings['input_ids']\n","        attention_masks = encodings['attention_mask']\n","        \n","        validation_inputs = torch.tensor(input_ids)\n","        validation_masks = torch.tensor(attention_masks)\n","        \n","        validation_data = TensorDataset(validation_inputs, validation_masks)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=14)\n","        \n","        num_labels = 1    \n","        pred_labels = []\n","        for i, batch in enumerate(validation_dataloader):\n","            batch = tuple(t.to(self.device) for t in batch)\n","            b_input_ids, b_input_mask = batch\n","            with torch.no_grad():\n","                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","                b_logit_pred = outs[0]\n","\n","                pred_label = torch.sigmoid(b_logit_pred)\n","\n","                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","                pred_label = pred_label.to(self.device).cpu().numpy()\n","\n","            pred_labels.append(pred_label)\n","\n","        pred_labels = [item for sublist in pred_labels for item in sublist]\n","\n","        threshold = 0.75\n","        pred_bools = [pl>threshold for pl in pred_labels]\n","        return pred_bools[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37W7x1dnBMYE"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import *\n","from tqdm import tqdm, trange\n","from ast import literal_eval\n","\n","\n","class LexisClassifier:\n","    def __init__(self):\n","        self.tokenizer = RobertaTokenizer.from_pretrained('sberbank-ai/ruRoberta-large', do_lower_case=False) \n","        state_dict = torch.load(f\"{DRIVE_PREFIX}/roberta_lexis_14_epochs\")\n","        self.model = RobertaForSequenceClassification.from_pretrained(\"sberbank-ai/ruRoberta-large\", state_dict=state_dict, num_labels=1)\n","\n","        self.model.load_state_dict(state_dict)\n","        self.device = 'cuda'\n","        self.model.cuda()\n","    \n","    def __call__(self, sentence):\n","        texts = [sentence]\n","        encodings = self.tokenizer.batch_encode_plus(texts, padding='longest')\n","        input_ids = encodings['input_ids']\n","        attention_masks = encodings['attention_mask']\n","        \n","        validation_inputs = torch.tensor(input_ids)\n","        validation_masks = torch.tensor(attention_masks)\n","        \n","        validation_data = TensorDataset(validation_inputs, validation_masks)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=14)\n","        \n","        num_labels = 1    \n","        pred_labels = []\n","        for i, batch in enumerate(validation_dataloader):\n","            batch = tuple(t.to(self.device) for t in batch)\n","            b_input_ids, b_input_mask = batch\n","            with torch.no_grad():\n","                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","                b_logit_pred = outs[0]\n","\n","                pred_label = torch.sigmoid(b_logit_pred)\n","\n","                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","                pred_label = pred_label.to(self.device).cpu().numpy()\n","\n","            pred_labels.append(pred_label)\n","\n","        pred_labels = [item for sublist in pred_labels for item in sublist]\n","\n","        threshold = 0.73\n","        pred_bools = [pl>threshold for pl in pred_labels]\n","        return pred_bools[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pXJm8bGlBMYE"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import *\n","from tqdm import tqdm, trange\n","from ast import literal_eval\n","\n","\n","class MorphologyClassifier:\n","    def __init__(self):\n","        self.tokenizer = RobertaTokenizer.from_pretrained('sberbank-ai/ruRoberta-large', do_lower_case=False) \n","        state_dict = torch.load(f\"{DRIVE_PREFIX}/roberta_morphology_6_epochs\")\n","        self.model = RobertaForSequenceClassification.from_pretrained(\"sberbank-ai/ruRoberta-large\", state_dict=state_dict, num_labels=1)\n","\n","        self.model.load_state_dict(state_dict)\n","        self.device = 'cuda'\n","        self.model.cuda()\n","    \n","    def __call__(self, sentence):\n","        texts = [sentence]\n","        encodings = self.tokenizer.batch_encode_plus(texts, padding='longest')\n","        input_ids = encodings['input_ids']\n","        attention_masks = encodings['attention_mask']\n","        \n","        validation_inputs = torch.tensor(input_ids)\n","        validation_masks = torch.tensor(attention_masks)\n","        \n","        validation_data = TensorDataset(validation_inputs, validation_masks)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=14)\n","        \n","        num_labels = 1    \n","        pred_labels = []\n","        for i, batch in enumerate(validation_dataloader):\n","            batch = tuple(t.to(self.device) for t in batch)\n","            b_input_ids, b_input_mask = batch\n","            with torch.no_grad():\n","                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","                b_logit_pred = outs[0]\n","\n","                pred_label = torch.sigmoid(b_logit_pred)\n","\n","                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","                pred_label = pred_label.to(self.device).cpu().numpy()\n","\n","            pred_labels.append(pred_label)\n","\n","        pred_labels = [item for sublist in pred_labels for item in sublist]\n","\n","        threshold = 0.64\n","        pred_bools = [pl>threshold for pl in pred_labels]\n","        return pred_bools[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaBtqskCBMYE"},"outputs":[],"source":["from transformers import RobertaForSequenceClassification\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","from transformers import *\n","from tqdm import tqdm, trange\n","from ast import literal_eval\n","\n","\n","class CommonsenseClassifier:\n","    def __init__(self):\n","        self.tokenizer = RobertaTokenizer.from_pretrained('sberbank-ai/ruRoberta-large', do_lower_case=False) \n","        state_dict = torch.load(f\"{DRIVE_PREFIX}/roberta_commonsense_4_epochs\")\n","        self.model = RobertaForSequenceClassification.from_pretrained(\"sberbank-ai/ruRoberta-large\", state_dict=state_dict, num_labels=1)\n","\n","        self.model.load_state_dict(state_dict)\n","        self.device = 'cuda'\n","        self.model.cuda()\n","    \n","    def __call__(self, sentence):\n","        texts = [sentence]\n","        encodings = self.tokenizer.batch_encode_plus(texts, padding='longest')\n","        input_ids = encodings['input_ids']\n","        attention_masks = encodings['attention_mask']\n","        \n","        validation_inputs = torch.tensor(input_ids)\n","        validation_masks = torch.tensor(attention_masks)\n","        \n","        validation_data = TensorDataset(validation_inputs, validation_masks)\n","        validation_sampler = SequentialSampler(validation_data)\n","        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=14)\n","        \n","        num_labels = 1    \n","        pred_labels = []\n","        for i, batch in enumerate(validation_dataloader):\n","            batch = tuple(t.to(self.device) for t in batch)\n","            b_input_ids, b_input_mask = batch\n","            with torch.no_grad():\n","                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","                b_logit_pred = outs[0]\n","\n","                pred_label = torch.sigmoid(b_logit_pred)\n","\n","                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","                pred_label = pred_label.to(self.device).cpu().numpy()\n","\n","            pred_labels.append(pred_label)\n","\n","        pred_labels = [item for sublist in pred_labels for item in sublist]\n","\n","        threshold = 0.51\n","        pred_bools = [pl>threshold for pl in pred_labels]\n","        return pred_bools[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cN0z-x_sBMYE"},"outputs":[],"source":["from nltk.tokenize import sent_tokenize\n","from tqdm import tqdm\n","\n","class RuColaMetric:\n","    def __init__(self):\n","        self.global_weight = 0.2\n","        self.machine_weight = 0.2\n","        \n","        self.global_f1 = 0.83\n","        self.machine_f1 = 0.86\n","        \n","        self.semantics_weight = 0.1\n","        self.syntax_weight = 0.1\n","        self.hallucination_weight = 0.1\n","        self.lexis_weight = 0.1\n","        self.morphology_weight = 0.1\n","        self.commonsense_weight = 0.1\n","        \n","        self.semantics_f1 = 0.43\n","        self.syntax_f1 = 0.67\n","        self.hallucination_f1 = 0.51\n","        self.lexis_f1 = 0.33\n","        self.morphology_f1 = 0.31\n","        self.commonsense_f1 = 0.21\n","        \n","        self.normalize_base = (\n","            self.global_weight * self.global_f1 \n","            + self.machine_weight * self.machine_f1\n","            + self.syntax_weight * self.syntax_f1\n","            + self.hallucination_weight * self.hallucination_f1\n","            + self.semantics_weight * self.semantics_f1\n","            + self.morphology_weight * self.morphology_f1\n","            + self.commonsense_weight * self.commonsense_f1\n","            + self.lexis_weight * self.lexis_f1\n","        )\n","        \n","        self.global_classifier = GlobalClassifier()\n","        self.machine_text_classifier = MachineClassifier()\n","        \n","        self.semantics_classifier = SemanticsClassifier()\n","        self.syntax_classifier = SyntaxClassifier()\n","        self.hallucination_classifier = HallucinationClassifier()\n","        self.lexis_classifier = LexisClassifier()\n","        self.morphology_classifier = MorphologyClassifier()\n","        self.commonsense_classifier = CommonsenseClassifier()\n","\n","    def pretify(self, model_res):\n","        results_copy = copy.deepcopy(model_res)\n","        temp_result_separate = []\n","        for temp_result in results_copy[\"separate\"]:\n","            temp_result_separate.append(temp_result[0])\n","        temp_result_overall = results_copy[\"overall\"][0]\n","        temp_result_separate_full = []\n","        for temp_result_array in results_copy[\"separate_full\"]:\n","            temp_result_separate_full.append([])\n","            for temp_result in temp_result_array:\n","                temp_dict = {}\n","                for key, val in temp_result.items():\n","                    if key == 'metric':\n","                        temp_dict[key] = val[0]\n","                    else:\n","                        temp_dict[key] = int(math.ceil(val[0]))\n","                temp_result_separate_full[-1].append(temp_dict)\n","        return {\"overall\": temp_result_overall, \"separate\": temp_result_separate, \"separate_full\": temp_result_separate_full}\n","\n","        \n","    def __call__(self, input_texts):\n","        result = {\"overall\": None, \"separate\": [], \"separate_full\": []}\n","        for text in tqdm(input_texts):\n","            sentences = sent_tokenize(text, language='russian')\n"," \n","            error_sum = 0\n","            result[\"separate_full\"].append([])\n","            for sentence in sentences:\n","                is_wrong = ((self.global_classifier(sentence) + 1) % 2) * self.global_weight * self.global_f1\n","                is_machine = self.machine_text_classifier(sentence) * self.machine_weight * self.machine_f1\n","                syntax = self.syntax_classifier(sentence) * self.syntax_weight * self.syntax_f1\n","                semantics = self.semantics_classifier(sentence) * self.semantics_weight * self.semantics_f1\n","                lexis = self.lexis_classifier(sentence) * self.lexis_weight * self.lexis_f1\n","                morphology = self.morphology_classifier(sentence) * self.morphology_weight * self.morphology_f1\n","                commonsense = self.commonsense_classifier(sentence) * self.commonsense_weight * self.commonsense_f1\n","                hallucination = self.hallucination_classifier(sentence) * self.hallucination_weight * self.hallucination_f1\n","                \n","                error_sum += is_wrong\n","                error_sum += is_machine\n","                error_sum += syntax\n","                error_sum += semantics\n","                error_sum += lexis\n","                error_sum += morphology\n","                error_sum += commonsense\n","                error_sum += hallucination\n","                \n","                result[\"separate_full\"][-1].append({\n","                    \"is_wrong\": is_wrong,\n","                    \"is_machine\": is_machine,\n","                    \"syntax\": syntax,\n","                    \"semantics\": semantics,\n","                    \"lexis\": lexis,\n","                    \"morphology\": morphology,\n","                    \"commonsense\": commonsense,\n","                    \"hallucination\": hallucination,\n","                    \"metric\": 1.0 - (is_wrong + is_machine + syntax + semantics + lexis + morphology + commonsense + hallucination)/self.normalize_base\n","                })\n","            error = (error_sum / self.normalized_bas) / len(sentences)\n","            result[\"separate\"].append(1.0 - error)\n","        \n","        error_sum = 0\n","        for error in result[\"separate\"]:\n","            error_sum += error\n","        result[\"overall\"] = error_sum / len(result[\"separate\"])\n","        \n","        return self.pretify(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfHJV71dBMYF","executionInfo":{"status":"ok","timestamp":1656975445188,"user_tz":-180,"elapsed":188348,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"35c5c314-5463-42ad-8dbd-68191c97af64"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/01c769031f99defa27c759f85c0f21715d1506ed5c4ab01f7d7ef8c8b3b5674a.10df436f410c7709f54ad2bf7e973429f03c613012be0df709996d5aef3706af\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/6d742b9584f250f0088e6a6674f80ae706d8a390d6bc30f7cfaccb4292556f55.e4807b2d97082a2dfbf6623d7aa973a5057f87e44b329ec0b63daafd5d2ef593\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"sberbank-ai/ruRoberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/home/jovyan/models/roberta/roberta_l\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/57935eccbb92bb4e5465411da844aeb075cac5b8c255c770a81463fa909d8ccc.f03af7b16e88082afbdd696d0647fe6bf624c0776d71dcece2b0e9973d081b26\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at sberbank-ai/ruRoberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/01c769031f99defa27c759f85c0f21715d1506ed5c4ab01f7d7ef8c8b3b5674a.10df436f410c7709f54ad2bf7e973429f03c613012be0df709996d5aef3706af\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/6d742b9584f250f0088e6a6674f80ae706d8a390d6bc30f7cfaccb4292556f55.e4807b2d97082a2dfbf6623d7aa973a5057f87e44b329ec0b63daafd5d2ef593\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"sberbank-ai/ruRoberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/home/jovyan/models/roberta/roberta_l\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/57935eccbb92bb4e5465411da844aeb075cac5b8c255c770a81463fa909d8ccc.f03af7b16e88082afbdd696d0647fe6bf624c0776d71dcece2b0e9973d081b26\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at sberbank-ai/ruRoberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/01c769031f99defa27c759f85c0f21715d1506ed5c4ab01f7d7ef8c8b3b5674a.10df436f410c7709f54ad2bf7e973429f03c613012be0df709996d5aef3706af\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/6d742b9584f250f0088e6a6674f80ae706d8a390d6bc30f7cfaccb4292556f55.e4807b2d97082a2dfbf6623d7aa973a5057f87e44b329ec0b63daafd5d2ef593\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"sberbank-ai/ruRoberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/home/jovyan/models/roberta/roberta_l\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/57935eccbb92bb4e5465411da844aeb075cac5b8c255c770a81463fa909d8ccc.f03af7b16e88082afbdd696d0647fe6bf624c0776d71dcece2b0e9973d081b26\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at sberbank-ai/ruRoberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/01c769031f99defa27c759f85c0f21715d1506ed5c4ab01f7d7ef8c8b3b5674a.10df436f410c7709f54ad2bf7e973429f03c613012be0df709996d5aef3706af\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/6d742b9584f250f0088e6a6674f80ae706d8a390d6bc30f7cfaccb4292556f55.e4807b2d97082a2dfbf6623d7aa973a5057f87e44b329ec0b63daafd5d2ef593\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"sberbank-ai/ruRoberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/home/jovyan/models/roberta/roberta_l\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/57935eccbb92bb4e5465411da844aeb075cac5b8c255c770a81463fa909d8ccc.f03af7b16e88082afbdd696d0647fe6bf624c0776d71dcece2b0e9973d081b26\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at sberbank-ai/ruRoberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/01c769031f99defa27c759f85c0f21715d1506ed5c4ab01f7d7ef8c8b3b5674a.10df436f410c7709f54ad2bf7e973429f03c613012be0df709996d5aef3706af\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/6d742b9584f250f0088e6a6674f80ae706d8a390d6bc30f7cfaccb4292556f55.e4807b2d97082a2dfbf6623d7aa973a5057f87e44b329ec0b63daafd5d2ef593\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"sberbank-ai/ruRoberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/home/jovyan/models/roberta/roberta_l\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/57935eccbb92bb4e5465411da844aeb075cac5b8c255c770a81463fa909d8ccc.f03af7b16e88082afbdd696d0647fe6bf624c0776d71dcece2b0e9973d081b26\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at sberbank-ai/ruRoberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/01c769031f99defa27c759f85c0f21715d1506ed5c4ab01f7d7ef8c8b3b5674a.10df436f410c7709f54ad2bf7e973429f03c613012be0df709996d5aef3706af\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/6d742b9584f250f0088e6a6674f80ae706d8a390d6bc30f7cfaccb4292556f55.e4807b2d97082a2dfbf6623d7aa973a5057f87e44b329ec0b63daafd5d2ef593\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"sberbank-ai/ruRoberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/home/jovyan/models/roberta/roberta_l\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/57935eccbb92bb4e5465411da844aeb075cac5b8c255c770a81463fa909d8ccc.f03af7b16e88082afbdd696d0647fe6bf624c0776d71dcece2b0e9973d081b26\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at sberbank-ai/ruRoberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/01c769031f99defa27c759f85c0f21715d1506ed5c4ab01f7d7ef8c8b3b5674a.10df436f410c7709f54ad2bf7e973429f03c613012be0df709996d5aef3706af\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/6d742b9584f250f0088e6a6674f80ae706d8a390d6bc30f7cfaccb4292556f55.e4807b2d97082a2dfbf6623d7aa973a5057f87e44b329ec0b63daafd5d2ef593\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"sberbank-ai/ruRoberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/home/jovyan/models/roberta/roberta_l\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/57935eccbb92bb4e5465411da844aeb075cac5b8c255c770a81463fa909d8ccc.f03af7b16e88082afbdd696d0647fe6bf624c0776d71dcece2b0e9973d081b26\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at sberbank-ai/ruRoberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/01c769031f99defa27c759f85c0f21715d1506ed5c4ab01f7d7ef8c8b3b5674a.10df436f410c7709f54ad2bf7e973429f03c613012be0df709996d5aef3706af\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/6d742b9584f250f0088e6a6674f80ae706d8a390d6bc30f7cfaccb4292556f55.e4807b2d97082a2dfbf6623d7aa973a5057f87e44b329ec0b63daafd5d2ef593\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"sberbank-ai/ruRoberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/191cf2edd2e8d2007f9a39479b45315ac1b79fe23fa4786511de1c8f9b9def46.ebd71ffa9cb74c7d1d39cf67343e2ae8465e2091f9fb70dbd5dec0cf58b1b60b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/home/jovyan/models/roberta/roberta_l\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/sberbank-ai/ruRoberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/57935eccbb92bb4e5465411da844aeb075cac5b8c255c770a81463fa909d8ccc.f03af7b16e88082afbdd696d0647fe6bf624c0776d71dcece2b0e9973d081b26\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at sberbank-ai/ruRoberta-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]}],"source":["rucola_metric = RuColaMetric()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3dsoFZfBMYF"},"outputs":[],"source":["DATA_LENGTH = 5625\n","data_sum = pd.read_json(f\"{DRIVE_PREFIX}/gazeta_jsonl/gazeta_val.jsonl\", dtype={ 'text': str, 'summary': str }, nrows=DATA_LENGTH, lines=True)\n","data_sum = data_sum[['text', 'summary']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGR5O7YgBMYF"},"outputs":[],"source":["text_data = [{\"text\": text} for text in data_sum[\"text\"]]\n","predictions = []\n","with open(f\"{DRIVE_PREFIX}/MBartSummarizerOutput.txt\", 'r') as file:\n","    for line in file:\n","        predictions.append(line)\n","data_sum = data_sum.assign(mbart_gazeta_summary=predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uPXo0SHNBMYF","executionInfo":{"status":"ok","timestamp":1656975447898,"user_tz":-180,"elapsed":7,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"3b233843-ede4-4945-fe59-29746b6e53a9"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":16}],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"markdown","source":["# Обработка сгенерированного пересказа"],"metadata":{"id":"R_Ji4nmp5NyN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pSvjACKBMYF","executionInfo":{"status":"ok","timestamp":1656977813523,"user_tz":-180,"elapsed":2365630,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"0cc05690-5087-4a5d-f2c5-8204eee36078"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5265/5265 [39:25<00:00,  2.23it/s]\n"]}],"source":["from nltk.tokenize import sent_tokenize\n","\n","result = rucola_metric(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXjtUw_FBMYF","executionInfo":{"status":"ok","timestamp":1656993445232,"user_tz":-180,"elapsed":246,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"d123ac5d-e280-47e4-b134-c8ff710183a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.7903067486800428\n"]}],"source":["print(result[\"overall\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"r4hx4TAxBMYG","executionInfo":{"status":"ok","timestamp":1656993450271,"user_tz":-180,"elapsed":779,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"7979e06d-0da2-4168-e92a-ba21079f03fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Freedman–Diaconis number of bins: 37\n"]},{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Метрика')"]},"metadata":{},"execution_count":49},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","%matplotlib inline\n","\n","np.random.seed(42)\n","x = np.random.normal(size=1000)\n","\n","result_per_sentence = result[\"separate\"]\n","\n","q25, q75 = np.percentile(x, [25, 75])\n","bin_width = 2 * (q75 - q25) * len(x) ** (-1/3)\n","bins = round((x.max() - x.min()) / bin_width)\n","print(\"Freedman–Diaconis number of bins:\", bins)\n","plt.hist(x, bins=bins);\n","\n","plt.hist(x, density=True, bins=bins)\n","plt.ylabel('Частота')\n","plt.xlabel('Метрика')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-yjr1KFBMYG","executionInfo":{"status":"ok","timestamp":1656977878260,"user_tz":-180,"elapsed":3,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"f55c22fb-4a3d-4cb4-d98e-062bd01b0f76"},"outputs":[{"output_type":"stream","name":"stdout","text":["is_wrong: 0.1430817610062893, 2002 out of 13992\n","is_machine: 0.4944968553459119, 6919 out of 13992\n","syntax: 0.04552601486563751, 637 out of 13992\n","semantics: 0.00357347055460263, 50 out of 13992\n","lexis: 0.1996140651801029, 2793 out of 13992\n","morphology: 0.0067181246426529445, 94 out of 13992\n","commonsense: 0.0370926243567753, 519 out of 13992\n","hallucination: 0.000714694110920526, 10 out of 13992\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","%matplotlib inline\n","\n","np.random.seed(42)\n","x = np.random.normal(size=1000)\n","\n","import collections\n","\n","true_counts = collections.defaultdict(int)\n","\n","labels = [\"is_wrong\", \"is_machine\", \"syntax\", \"semantics\", \"lexis\", \"morphology\", \"commonsense\", \"hallucination\"]\n","counter = 0\n","\n","result_per_sentence = []\n","for element in result[\"separate_full\"]:\n","    for inner_element in element:\n","        counter += 1\n","        for label in labels:\n","            true_counts[label] += int(math.ceil(inner_element[label]))\n","\n","for label in labels:\n","    print(f\"{label}: {true_counts[label]/counter}, {true_counts[label]} out of {counter}\")"]},{"cell_type":"code","source":["with open(f\"{DRIVE_PREFIX}/metrics_output.txt\", 'w+') as file:\n","    print(result, file=file)"],"metadata":{"id":"4GKhoMRySSYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ND-AVasGUBj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCdBZgqkBMYG"},"outputs":[],"source":["metrics_results.loc[0][\"RUCOLA_METRIC\"] = result[\"overall\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6utFzX8BMYG","outputId":"15d1a513-3c55-438c-8d11-e972931de759"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BLEU</th>\n","      <th>ROUGE_1</th>\n","      <th>ROUGE_2</th>\n","      <th>ROUGE_L</th>\n","      <th>ROUGE_L_SUM</th>\n","      <th>METEOR</th>\n","      <th>RUCOLA_METRIC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.089435</td>\n","      <td>0.216972</td>\n","      <td>0.055424</td>\n","      <td>0.210877</td>\n","      <td>0.210657</td>\n","      <td>0.294488</td>\n","      <td>0.729557</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       BLEU   ROUGE_1   ROUGE_2   ROUGE_L  ROUGE_L_SUM    METEOR  \\\n","0  0.089435  0.216972  0.055424  0.210877     0.210657  0.294488   \n","\n","   RUCOLA_METRIC  \n","0       0.729557  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["metrics_results.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4xVDLkhBMYG","executionInfo":{"status":"ok","timestamp":1656973176709,"user_tz":-180,"elapsed":1433,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"a87a23a8-1c34-4234-b264-0c1b453d3d4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["5265\n"]}],"source":["print(len(result[\"separate\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XfUpHTdSBMYG"},"outputs":[],"source":["result_for_sentences = []\n","array_for_sentences = []\n","for element in result[\"separate\"]:\n","    result_for_sentences.append(element)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHpjTmaDBMYH"},"outputs":[],"source":["data_sum = data_sum.assign(RuCoLA_metric=result_for_sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":4645},"id":"ch8he598BMYH","executionInfo":{"status":"ok","timestamp":1656992582561,"user_tz":-180,"elapsed":265,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"dd2e5b86-8959-4799-ebf6-21088df70443"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  \\\n","0  После громких приобретений Андре Шюррле, Гуса ...   \n","1  Американское издание The National Interest оце...   \n","2  Министр иностранных дел России Сергей Лавров с...   \n","3  Минфин предложил с января 2020 года увеличить ...   \n","4  Заявление командующего военно-воздушными силам...   \n","\n","                                             summary  \\\n","0  Московский «Спартак» продолжает активную транс...   \n","1  Издание The National Interest оценило перспект...   \n","2  Глава МИД России Сергей Лавров заявил, что в 2...   \n","3  Министерство финансов предлагает вдвое поднять...   \n","4  Американские ПВО провалились в Саудовской Арав...   \n","\n","                                mbart_gazeta_summary  RuCoLA_metric  \n","0  Московский «Спартак» не планирует закрывать ле...       0.882991  \n","1  Американское издание The National Interest оце...       0.535103  \n","2  Министр иностранных дел России Сергей Лавров з...       0.852740  \n","3  Минфин предлагает с 2020 года увеличить сбор з...       1.000000  \n","4  Заявление командующего военно-воздушными силам...       0.834760  "],"text/html":["\n","  <div id=\"df-d218aeb2-65f5-4969-9ec2-ab753de10372\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>summary</th>\n","      <th>mbart_gazeta_summary</th>\n","      <th>RuCoLA_metric</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>После громких приобретений Андре Шюррле, Гуса ...</td>\n","      <td>Московский «Спартак» продолжает активную транс...</td>\n","      <td>Московский «Спартак» не планирует закрывать ле...</td>\n","      <td>0.882991</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Американское издание The National Interest оце...</td>\n","      <td>Издание The National Interest оценило перспект...</td>\n","      <td>Американское издание The National Interest оце...</td>\n","      <td>0.535103</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Министр иностранных дел России Сергей Лавров с...</td>\n","      <td>Глава МИД России Сергей Лавров заявил, что в 2...</td>\n","      <td>Министр иностранных дел России Сергей Лавров з...</td>\n","      <td>0.852740</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Минфин предложил с января 2020 года увеличить ...</td>\n","      <td>Министерство финансов предлагает вдвое поднять...</td>\n","      <td>Минфин предлагает с 2020 года увеличить сбор з...</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Заявление командующего военно-воздушными силам...</td>\n","      <td>Американские ПВО провалились в Саудовской Арав...</td>\n","      <td>Заявление командующего военно-воздушными силам...</td>\n","      <td>0.834760</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d218aeb2-65f5-4969-9ec2-ab753de10372')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d218aeb2-65f5-4969-9ec2-ab753de10372 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d218aeb2-65f5-4969-9ec2-ab753de10372');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}],"source":["data_sum.head()"]},{"cell_type":"code","source":["data_sum.to_csv(f\"{DRIVE_PREFIX}/df_with_metric.csv\", sep='\\t')"],"metadata":{"id":"qtEiCTfZXPBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ic3kbSqzBMYH"},"outputs":[],"source":["import copy\n","\n","results_copy = copy.deepcopy(result)"]},{"cell_type":"code","source":["# Вывод до правок в формате вывода\n","print(results_copy[\"separate\"][:3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Od8nsSxUU8_","executionInfo":{"status":"ok","timestamp":1656977941488,"user_tz":-180,"elapsed":2,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"ec364c5c-5a9f-4fd7-9453-c91129910115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[array([0.93166667]), array([0.7285]), array([0.914])]\n"]}]},{"cell_type":"code","source":["temp_result_separate = []\n","for temp_result in results_copy[\"separate\"]:\n","    temp_result_separate.append(temp_result[0])"],"metadata":{"id":"tHVZG5X9Uc9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp_result_overall = results_copy[\"overall\"][0]"],"metadata":{"id":"3mRhOegJUr2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Вывод до правок в формате вывода\n","print(results_copy[\"separate_full\"][:3])\n","temp_result_separate_full = []\n","for temp_result_array in results_copy[\"separate_full\"]:\n","    temp_result_separate_full.append([])\n","    for temp_result in temp_result_array:\n","        temp_dict = {}\n","        for key, val in temp_result.items():\n","            if key == 'metric':\n","                temp_dict[key] = val[0]\n","            else:\n","                temp_dict[key] = int(math.ceil(val[0]))\n","        temp_result_separate_full[-1].append(temp_dict)\n","print(temp_result_separate_full[:3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pm3iF23OUyrx","executionInfo":{"status":"ok","timestamp":1656977947022,"user_tz":-180,"elapsed":603,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"e6fdbcdd-ca59-4bde-d6df-102c2d5ffa8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.033]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([0.94349315])}, {'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}, {'is_wrong': array([0.]), 'is_machine': array([0.172]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([0.70547945])}], [{'is_wrong': array([0.]), 'is_machine': array([0.172]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([0.70547945])}, {'is_wrong': array([0.166]), 'is_machine': array([0.172]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.033]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([0.36472603])}], [{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}, {'is_wrong': array([0.]), 'is_machine': array([0.172]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([0.70547945])}]]\n","[[{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 1, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 0.9434931506849316}, {'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}, {'is_wrong': 0, 'is_machine': 1, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 0.7054794520547945}], [{'is_wrong': 0, 'is_machine': 1, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 0.7054794520547945}, {'is_wrong': 1, 'is_machine': 1, 'syntax': 0, 'semantics': 0, 'lexis': 1, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 0.36472602739726034}], [{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}, {'is_wrong': 0, 'is_machine': 1, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 0.7054794520547945}]]\n"]}]},{"cell_type":"code","source":["pretty_result = {\"overall\": temp_result_overall, \"separate\": temp_result_separate, \"separate_full\": temp_result_separate_full}"],"metadata":{"id":"2JA_OZu2Ur-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(f\"{DRIVE_PREFIX}/metrics_output_pretty.txt\", 'w+') as file:\n","    print(result, file=file)"],"metadata":{"id":"TWSd4s_UWDdr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_avg = 0\n","for val in result[\"separate\"]:\n","    result_avg += val\n","result_avg = (result_avg / len(result[\"separate\"]))**2\n","\n","disp = 0\n","result_avg_sqr = 0\n","for val in result[\"separate\"]:\n","    result_avg_sqr += val*val\n","result_avg_sqr /= len(result[\"separate\"])\n","disp = result_avg_sqr - result_avg"],"metadata":{"id":"erAkW2vD4RQK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(disp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TOw443O5Zk7","executionInfo":{"status":"ok","timestamp":1656993149897,"user_tz":-180,"elapsed":2,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"09a461e4-207b-4fee-c834-ca4395287670"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.014091604946987246\n"]}]},{"cell_type":"code","source":["bad_examples = [\n","                \"Полностью правильное предложение.\",\n","                \"Краене ниграматное, придлажение.\",\n","                \"Чут менее неграмотное придлажение.\",\n","                \"Покупатели магазина стали невольными зрителями этого происшествия.\", # Семантическая ошибка\n","                \"Более неуверенные в себе люди часто одиноки.\", # Семантическая ошибка\n","                \"Солнце уже села, когда мы вернулись.\", # Синтаксическая ошибка\n","                \"В этом деле играет значение каждая мелочь.\", # Синтаксическая ошибка\n","                \"Он пришёл в пальте.\", # Морфологическая ошибка\n","                \"На столе лежали две пары чулков\", # Морфологическая ошибка\n","                \"Будем бороться до последнего издыхания.\", # Лексическая ошибка\n","                \"Не удалось дозвониться до абонемента.\", # Лексическая ошибка\n","]"],"metadata":{"id":"cBB0rgqyYA_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bad_result = rucola_metric(bad_examples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nc-4bLObX_tT","executionInfo":{"status":"ok","timestamp":1656978383027,"user_tz":-180,"elapsed":3364,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"1815b970-c847-41b2-d17b-f94203f0bb49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 11/11 [00:01<00:00,  5.83it/s]\n"]}]},{"cell_type":"code","source":["def pretify(model_res):\n","    results_copy = copy.deepcopy(model_res)\n","    temp_result_separate = []\n","    for temp_result in results_copy[\"separate\"]:\n","        temp_result_separate.append(temp_result[0])\n","    temp_result_overall = results_copy[\"overall\"][0]\n","    temp_result_separate_full = []\n","    for temp_result_array in results_copy[\"separate_full\"]:\n","        temp_result_separate_full.append([])\n","        for temp_result in temp_result_array:\n","            temp_dict = {}\n","            for key, val in temp_result.items():\n","                if key == 'metric':\n","                    temp_dict[key] = val[0]\n","                else:\n","                    temp_dict[key] = int(math.ceil(val[0]))\n","            temp_result_separate_full[-1].append(temp_dict)\n","    return {\"overall\": temp_result_overall, \"separate\": temp_result_separate, \"separate_full\": temp_result_separate_full}\n"],"metadata":{"id":"Ym6oj3WmZfxH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(bad_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzyjUUNTZY1s","executionInfo":{"status":"ok","timestamp":1656978388923,"user_tz":-180,"elapsed":839,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"556455b8-35d0-4469-b012-2641c3985171"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'overall': array([0.89481818]), 'separate': [array([1.]), array([0.47]), array([0.803]), array([1.]), array([1.]), array([0.767]), array([1.]), array([0.803]), array([1.]), array([1.]), array([1.])], 'separate_full': [[{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}], [{'is_wrong': array([0.166]), 'is_machine': array([0.172]), 'syntax': array([0.067]), 'semantics': array([0.043]), 'lexis': array([0.]), 'morphology': array([0.031]), 'commonsense': array([0.]), 'hallucination': array([0.051]), 'metric': array([0.09246575])}], [{'is_wrong': array([0.166]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.031]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([0.66267123])}], [{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}], [{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}], [{'is_wrong': array([0.166]), 'is_machine': array([0.]), 'syntax': array([0.067]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([0.6010274])}], [{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}], [{'is_wrong': array([0.166]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.031]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([0.66267123])}], [{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}], [{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}], [{'is_wrong': array([0.]), 'is_machine': array([0.]), 'syntax': array([0.]), 'semantics': array([0.]), 'lexis': array([0.]), 'morphology': array([0.]), 'commonsense': array([0.]), 'hallucination': array([0.]), 'metric': array([1.])}]]}\n"]}]},{"cell_type":"code","source":["print(pretify(bad_result))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sHa5IkPZ6ll","executionInfo":{"status":"ok","timestamp":1656978420935,"user_tz":-180,"elapsed":408,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"79458a38-af51-448e-89b4-93600cfa452f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'overall': 0.8948181818181818, 'separate': [1.0, 0.47, 0.8029999999999999, 1.0, 1.0, 0.767, 1.0, 0.8029999999999999, 1.0, 1.0, 1.0], 'separate_full': [[{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}], [{'is_wrong': 1, 'is_machine': 1, 'syntax': 1, 'semantics': 1, 'lexis': 0, 'morphology': 1, 'commonsense': 0, 'hallucination': 1, 'metric': 0.09246575342465757}], [{'is_wrong': 1, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 1, 'commonsense': 0, 'hallucination': 0, 'metric': 0.6626712328767124}], [{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}], [{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}], [{'is_wrong': 1, 'is_machine': 0, 'syntax': 1, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 0.601027397260274}], [{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}], [{'is_wrong': 1, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 1, 'commonsense': 0, 'hallucination': 0, 'metric': 0.6626712328767124}], [{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}], [{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}], [{'is_wrong': 0, 'is_machine': 0, 'syntax': 0, 'semantics': 0, 'lexis': 0, 'morphology': 0, 'commonsense': 0, 'hallucination': 0, 'metric': 1.0}]]}\n"]}]},{"cell_type":"markdown","source":["# Обработка эталона"],"metadata":{"id":"ZemoS4Ov44vA"}},{"cell_type":"code","source":["summaries = []\n","for text in data_sum[\"summary\"]:\n","    summaries.append(text)"],"metadata":{"id":"33O9qe9YnQ5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(summaries[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mb1pfuTXnhsP","executionInfo":{"status":"ok","timestamp":1656978554153,"user_tz":-180,"elapsed":3,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"bc281d2b-0e00-4070-96a0-53692d47f3f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Московский «Спартак» продолжает активную трансферную кампанию. Очередным новичком красно-белых может стать опорный полузащитник «Ниццы» Адриен Тамез.\n"]}]},{"cell_type":"code","source":["result = rucola_metric(summaries)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TakdU-NMnlGo","executionInfo":{"status":"ok","timestamp":1656981221142,"user_tz":-180,"elapsed":2623881,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"2db68287-f393-4186-e5df-895a79d3f840"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5265/5265 [43:43<00:00,  2.01it/s]\n"]}]},{"cell_type":"code","source":["result = pretify(result)"],"metadata":{"id":"416ltOeIr_Jl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(result[\"overall\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171},"id":"kIWVqg8wsDQG","executionInfo":{"status":"error","timestamp":1656990106707,"user_tz":-180,"elapsed":890,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"a6fa907f-8323-4b24-e1f4-168998a8abc4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f0ce2ccb151a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"overall\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"]}]},{"cell_type":"code","source":["with open(f\"{DRIVE_PREFIX}/metrics_etalon_output_pretty.txt\", 'w+') as file:\n","    print(result, file=file)"],"metadata":{"id":"dzDWrDOtsKhb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","%matplotlib inline\n","\n","np.random.seed(42)\n","x = np.random.normal(size=1000)\n","\n","result_per_sentence = []\n","for element in result[\"separate\"]:\n","    result_per_sentence.append(element)\n","x = np.array(result_per_sentence)\n","\n","q25, q75 = np.percentile(x, [25, 75])\n","bin_width = 2 * (q75 - q25) * len(x) ** (-1/3)\n","bins = round((x.max() - x.min()) / bin_width)\n","print(\"Freedman–Diaconis number of bins:\", bins)\n","plt.hist(x, bins=bins);\n","\n","plt.hist(x, density=True, bins=bins)  # density=False would make counts\n","plt.ylabel('Частота')\n","plt.xlabel('Метрика')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"Q-5VHq37x-M6","executionInfo":{"status":"ok","timestamp":1656993031906,"user_tz":-180,"elapsed":821,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"08c1f066-b86b-4059-a4c7-fa3d3b9f1ca1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Freedman–Diaconis number of bins: 32\n"]},{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Метрика')"]},"metadata":{},"execution_count":38},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","%matplotlib inline\n","\n","np.random.seed(42)\n","x = np.random.normal(size=1000)\n","\n","import collections\n","\n","true_counts = collections.defaultdict(int)\n","\n","labels = [\"is_wrong\", \"is_machine\", \"syntax\", \"semantics\", \"lexis\", \"morphology\", \"commonsense\", \"hallucination\"]\n","counter = 0\n","\n","result_per_sentence = []\n","for element in result[\"separate_full\"]:\n","    for inner_element in element:\n","        counter += 1\n","        for label in labels:\n","            true_counts[label] += int(math.ceil(inner_element[label]))\n","\n","for label in labels:\n","    print(f\"{label}: {true_counts[label]/counter}, {true_counts[label]} out of {counter}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTT5MFE_yO7R","executionInfo":{"status":"ok","timestamp":1656981374139,"user_tz":-180,"elapsed":1004,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"1a4f71b3-e653-485c-d14b-52c7ce9aac0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["is_wrong: 0.11777877295118674, 1841 out of 15631\n","is_machine: 0.43490499648135117, 6798 out of 15631\n","syntax: 0.04183993346554923, 654 out of 15631\n","semantics: 0.0031987716716780756, 50 out of 15631\n","lexis: 0.1755485893416928, 2744 out of 15631\n","morphology: 0.00467020664064999, 73 out of 15631\n","commonsense: 0.026101976840893097, 408 out of 15631\n","hallucination: 6.397543343356151e-05, 1 out of 15631\n"]}]},{"cell_type":"code","source":["pretty_result_avg = 0\n","for val in result[\"separate\"]:\n","    pretty_result_avg += val\n","pretty_result_avg = (pretty_result_avg / len(pretty_result[\"separate\"]))**2\n","\n","disp = 0\n","pretty_result_avg_sqr = 0\n","for val in result[\"separate\"]:\n","    pretty_result_avg_sqr += val*val\n","pretty_result_avg_sqr /= len(pretty_result[\"separate\"])\n","disp = pretty_result_avg_sqr - pretty_result_avg"],"metadata":{"id":"tCX-gJVm5jA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(disp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OALWQqF-5mJh","executionInfo":{"status":"ok","timestamp":1656983295182,"user_tz":-180,"elapsed":578,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"a014a3d1-0520-4adb-e1ff-183a3409d8fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0048060264167543165\n"]}]},{"cell_type":"markdown","source":["# Исправление смещения (технический раздел для исправления ошибки смещения в поле \"separate\" выхода метрики, был потерян нормализующий множитель)"],"metadata":{"id":"3dVhNv_YZKKh"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import json\n","import pickle"],"metadata":{"id":"P5KODLYSZJmm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = \"\"\n","with open(f\"{DRIVE_PREFIX}/metrics_output_pretty.txt\", 'r') as reader:\n","     # Read & print the entire file\n","    data = reader.read()"],"metadata":{"id":"u3szkRToZa8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data[:200])\n","data = data.replace(\"'\", \"\\\"\")\n","result = json.loads(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoM4epViZ7vf","executionInfo":{"status":"ok","timestamp":1656993396247,"user_tz":-180,"elapsed":309,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"ea093909-0a87-4668-9c39-3327a501db1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'overall': 0.7903067486800428, 'separate': [0.8829908675799086, 0.5351027397260273, 0.8527397260273973, 1.0, 0.8347602739726027, 0.7054794520547945, 0.5976027397260273, 0.7568493150684932, 0.82448630\n"]}]},{"cell_type":"code","source":["print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1oepSui6vd10VNCwIbwBhjHWasQv_f6zW"},"id":"0417EBXLaYw_","executionInfo":{"status":"ok","timestamp":1656991884750,"user_tz":-180,"elapsed":1051,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"eac768b1-b1c9-44af-b5fc-e42ee469470a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["global_weight = 0.2\n","machine_weight = 0.2\n","\n","global_f1 = 0.83\n","machine_f1 = 0.86\n","\n","semantics_weight = 0.1\n","syntax_weight = 0.1\n","hallucination_weight = 0.1\n","lexis_weight = 0.1\n","morphology_weight = 0.1\n","commonsense_weight = 0.1\n","\n","semantics_f1 = 0.43\n","syntax_f1 = 0.67\n","hallucination_f1 = 0.51\n","lexis_f1 = 0.33\n","morphology_f1 = 0.31\n","commonsense_f1 = 0.21\n","\n","normalize_base = (\n","    global_weight * global_f1 \n","    + machine_weight * machine_f1\n","    + syntax_weight * syntax_f1\n","    + hallucination_weight * hallucination_f1\n","    + semantics_weight * semantics_f1\n","    + morphology_weight * morphology_f1\n","    + commonsense_weight * commonsense_f1\n","    + lexis_weight * lexis_f1\n",")"],"metadata":{"id":"EbPPe_Y6ac60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, val in enumerate(result[\"separate\"]):\n","    result[\"separate\"][i] = (normalize_base - 1 + val) / normalize_base\n"],"metadata":{"id":"wXtqsrTYa5f2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["error_sum = 0\n","for val in result[\"separate\"]:\n","    error_sum += val\n","result[\"overall\"] = error_sum / len(result[\"separate\"])"],"metadata":{"id":"tHefC7gnce1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"15A02M7yNWVDoayFT-MXNEIXZkMNB6uXs"},"id":"w25-EGDGbQu7","executionInfo":{"status":"ok","timestamp":1656993404502,"user_tz":-180,"elapsed":475,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"0c9d01f9-7088-455e-c976-0d5ea6c5684c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Аналогично для эталона"],"metadata":{"id":"9CD5HbQhd7QR"}},{"cell_type":"code","source":["data = \"\"\n","with open(f\"{DRIVE_PREFIX}/metrics_etalon_output_pretty.txt\", 'r') as reader:\n","     # Read & print the entire file\n","    data = reader.read()"],"metadata":{"id":"3zJ6mUtmd-Uj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data[:200])\n","data = data.replace(\"'\", \"\\\"\")\n","result = json.loads(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrCfma8GeI9q","executionInfo":{"status":"ok","timestamp":1656993385402,"user_tz":-180,"elapsed":233,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"c0c063f1-2d6a-4609-a7e1-58bd8a397bb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'overall': 0.8172350346817652, 'separate': [0.9717465753424658, 0.5684931506849316, 0.6875, 0.9289383561643836, 0.7106164383561644, 0.779109589041096, 0.8105022831050228, 0.9018264840182648, 0.752996\n"]}]},{"cell_type":"code","source":["print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"11gl7C1NZh4OBZlPbzxSLqkhklJHZKyBK"},"id":"JMgjF-eCeLI1","executionInfo":{"status":"ok","timestamp":1656992915812,"user_tz":-180,"elapsed":1045,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"e123aad4-4e0a-4f9c-ae5e-c3f2e2b45713"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["global_weight = 0.2\n","machine_weight = 0.2\n","\n","global_f1 = 0.83\n","machine_f1 = 0.86\n","\n","semantics_weight = 0.1\n","syntax_weight = 0.1\n","hallucination_weight = 0.1\n","lexis_weight = 0.1\n","morphology_weight = 0.1\n","commonsense_weight = 0.1\n","\n","semantics_f1 = 0.43\n","syntax_f1 = 0.67\n","hallucination_f1 = 0.51\n","lexis_f1 = 0.33\n","morphology_f1 = 0.31\n","commonsense_f1 = 0.21\n","\n","normalize_base = (\n","    global_weight * global_f1 \n","    + machine_weight * machine_f1\n","    + syntax_weight * syntax_f1\n","    + hallucination_weight * hallucination_f1\n","    + semantics_weight * semantics_f1\n","    + morphology_weight * morphology_f1\n","    + commonsense_weight * commonsense_f1\n","    + lexis_weight * lexis_f1\n",")"],"metadata":{"id":"k1iDI2qneN7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, val in enumerate(result[\"separate\"]):\n","    result[\"separate\"][i] = (normalize_base - 1 + val) / normalize_base"],"metadata":{"id":"Ki34RS1MeQT9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["error_sum = 0\n","for val in result[\"separate\"]:\n","    error_sum += val\n","result[\"overall\"] = error_sum / len(result[\"separate\"])"],"metadata":{"id":"iMuKrOsDeSCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1DfV2qqZKq1pg7UAwMaOFj3r7AnTWfaqb"},"id":"4nHakQcceTxf","executionInfo":{"status":"ok","timestamp":1656992927283,"user_tz":-180,"elapsed":954,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"9710b2ca-12f6-4902-8e23-8feb6245ddb8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["with open(f\"{DRIVE_PREFIX}/metrics_etalon_output_pretty.txt\", 'w+') as file:\n","    print(result, file=file)"],"metadata":{"id":"SZ06rbnwfB9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(normalize_base)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-2L-boeiUct","executionInfo":{"status":"ok","timestamp":1656993981360,"user_tz":-180,"elapsed":317,"user":{"displayName":"811 Пономарев Артем","userId":"01964672788651008029"}},"outputId":"d8f96bc5-5e79-4a47-8861-ed0cc787122e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5840000000000001\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Diploma.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}